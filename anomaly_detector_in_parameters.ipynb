{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7r7El5Ut3zcOsxuDXjGQo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ihalagedara/optimization_agent/blob/main/anomaly_detector_in_parameters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BVR86GjOEXS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Load Data\n",
        "# -----------------------------\n",
        "# Good KPI parameter sets (rows = cells, cols = params)\n",
        "df_good = pd.read_csv(\"good_parameters.csv\")\n",
        "\n",
        "# Degraded parameter set (one row)\n",
        "df_bad = pd.read_csv(\"degraded_parameters.csv\")\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Preprocessing\n",
        "# -----------------------------\n",
        "scaler = StandardScaler()\n",
        "X_good = scaler.fit_transform(df_good.values)\n",
        "X_bad = scaler.transform(df_bad.values)\n",
        "\n",
        "n_features = X_good.shape[1]\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Build Autoencoder\n",
        "# -----------------------------\n",
        "input_layer = Input(shape=(n_features,))\n",
        "encoded = Dense(64, activation=\"relu\")(input_layer)\n",
        "encoded = Dense(32, activation=\"relu\")(encoded)\n",
        "bottleneck = Dense(8, activation=\"relu\")(encoded)  # compressed representation\n",
        "decoded = Dense(32, activation=\"relu\")(bottleneck)\n",
        "decoded = Dense(64, activation=\"relu\")(decoded)\n",
        "output_layer = Dense(n_features, activation=\"linear\")(decoded)\n",
        "\n",
        "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
        "autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss=\"mse\")\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Train Autoencoder\n",
        "# -----------------------------\n",
        "history = autoencoder.fit(\n",
        "    X_good, X_good,\n",
        "    epochs=100,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    validation_split=0.1,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Apply to Degraded Case\n",
        "# -----------------------------\n",
        "reconstructed = autoencoder.predict(X_bad)\n",
        "reconstruction_error = np.abs(X_bad - reconstructed)\n",
        "\n",
        "# -----------------------------\n",
        "# 6. Identify Abnormal Parameters\n",
        "# -----------------------------\n",
        "param_errors = reconstruction_error[0]\n",
        "param_importance = np.argsort(param_errors)[::-1]\n",
        "\n",
        "print(\"\\nParameters ranked by abnormality (highest error first):\")\n",
        "for idx in param_importance:\n",
        "    col = df_good.columns[idx]\n",
        "    diff = X_bad[0][idx] - reconstructed[0][idx]\n",
        "    direction = \"Increase\" if diff < 0 else \"Decrease\"\n",
        "    print(f\"- {col}: {direction} (Current={df_bad.iloc[0, idx]}, Suggestedâ‰ˆ{scaler.inverse_transform(reconstructed)[0][idx]:.2f})\")\n",
        "\n",
        "# -----------------------------\n",
        "# 7. Generate Suggested Parameter Values\n",
        "# -----------------------------\n",
        "# Replace degraded params with reconstructed values (closer to good configs)\n",
        "suggested_params = scaler.inverse_transform(reconstructed)\n",
        "suggested_df = pd.DataFrame(suggested_params, columns=df_good.columns)\n",
        "\n",
        "print(\"\\nSuggested new parameter values:\")\n",
        "print(suggested_df.round(2))\n"
      ],
      "metadata": {
        "id": "PHsiyED2OSuM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}